{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 1Saved\n",
      "Image 1Saved\n",
      "Image 1Saved\n",
      "Image 1Saved\n",
      "Image 1Saved\n",
      "Image 1Saved\n",
      "Image 1Saved\n",
      "Image 1Saved\n",
      "Image 1Saved\n",
      "Image 1Saved\n",
      "Image 1Saved\n",
      "Image 1Saved\n",
      "Image 1Saved\n",
      "Image 1Saved\n",
      "Image 1Saved\n",
      "Image 1Saved\n",
      "Image 1Saved\n",
      "Image 1Saved\n",
      "Image 1Saved\n",
      "Image 1Saved\n",
      "Image 1Saved\n",
      "Image 1Saved\n",
      "Image 1Saved\n",
      "Image 1Saved\n",
      "Image 2Saved\n",
      "Image 1Saved\n",
      "Image 2Saved\n",
      "Image 1Saved\n",
      "Image 2Saved\n",
      "Image 1Saved\n",
      "Image 1Saved\n",
      "Image 1Saved\n",
      "Image 1Saved\n",
      "Image 1Saved\n",
      "Image 1Saved\n",
      "Image 1Saved\n",
      "Image 1Saved\n",
      "Image 1Saved\n",
      "Image 1Saved\n",
      "Image 1Saved\n",
      "Image 1Saved\n",
      "Image 1Saved\n",
      "Image 1Saved\n",
      "Image 1Saved\n",
      "Image 1Saved\n",
      "Image 1Saved\n",
      "Image 1Saved\n",
      "Image 1Saved\n",
      "Image 1Saved\n",
      "Image 1Saved\n",
      "Image 1Saved\n",
      "Image 1Saved\n",
      "Image 1Saved\n",
      "Image 1Saved\n",
      "Image 1Saved\n",
      "Image 1Saved\n",
      "Image 1Saved\n",
      "Image 1Saved\n",
      "Image 1Saved\n",
      "Image 1Saved\n",
      "Image 1Saved\n",
      "Image 1Saved\n",
      "Image 1Saved\n",
      "Image 1Saved\n",
      "Image 1Saved\n",
      "Image 1Saved\n",
      "Image 1Saved\n",
      "Image 1Saved\n",
      "Image 1Saved\n",
      "Image 2Saved\n",
      "Image 1Saved\n",
      "Image 1Saved\n",
      "Image 1Saved\n",
      "Image 1Saved\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-1a9ac43593e7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;31m#cv2.imshow('Capturing Video',img)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mgrayImg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mfaces\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfaceCascade\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetectMultiScale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrayImg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1.04\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0mcnt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mkeyPressed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Let's load our Weapons !!\n",
    "\n",
    "import cv2\n",
    "\n",
    "video = cv2.VideoCapture(0)\n",
    "\n",
    "# Below are the Cascade Calassifier weights \n",
    "\n",
    "faceCascade = cv2.CascadeClassifier(\"C:/Users/Daya/Desktop/DataSets/HaarCascade/haarcascade_frontalface_default.xml\")\n",
    "smileCascade = cv2.CascadeClassifier(\"C:/Users/Daya/Desktop/DataSets/HaarCascade/haarcascade_smile.xml\")\n",
    "\n",
    "\n",
    "\n",
    "while True:\n",
    "    \n",
    "    # Read our video by taking images\n",
    "    success,img = video.read()\n",
    "    #cv2.imshow('Capturing Video',img)\n",
    "    \n",
    "    # For smile we dont need colors, so im converting it to gray if you want you can use 3 channels\n",
    "    \n",
    "    grayImg = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    \n",
    "    faces = faceCascade.detectMultiScale(grayImg,1.04,4)\n",
    "    cnt=1\n",
    "    \n",
    "    keyPressed = cv2.waitKey(1)\n",
    "\n",
    "    for x,y,w,h in faces:\n",
    "        \n",
    "        # faces contains coordinated of face, x,y are center points and w,h are width and height\n",
    "        \n",
    "        img = cv2.rectangle(img,(x,y),(x+w,y+h),(71, 157, 214),3)  # To show rectangle box on the detected face\n",
    "        \n",
    "        # In the face, we need smile only, to get that we use smilecascade classifier \n",
    "        \n",
    "        smiles = smileCascade.detectMultiScale(grayImg,4,15)\n",
    "        \n",
    "        # for this also we get center(x,y),width and height\n",
    "        \n",
    "        for x,y,w,h in smiles:\n",
    "            \n",
    "            # Plotting the rectangle box around the detected smile \n",
    "            \n",
    "            img = cv2.rectangle(img,(x,y),(x+w,y+h),(100,100,100),5)'\n",
    "            \n",
    "            # Below code is pretty much self explanatory, just saving the model \n",
    "            print(\"Image \"+str(cnt)+\"Saved\")\n",
    "            cv2.imshow('Smile',img)\n",
    "            path=r'C:\\Users\\Daya\\Desktop\\ML_Projects\\Opencv_images\\img'+str(cnt)+'.jpg'\n",
    "            cv2.imwrite(path,img)\n",
    "            cnt +=1\n",
    "            if(cnt>=2):    \n",
    "                break\n",
    "      \n",
    "    \n",
    "    cv2.imshow('live video',img)\n",
    "    if(keyPressed & 0xFF==ord('q')):\n",
    "        break\n",
    "\n",
    "# Dont forget to add these two lines otherwise your program will not release camera \n",
    "\n",
    "video.release()                                  \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "video.release()                                  \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
